# streamlit run app.py
import os
import json
from pathlib import Path

import streamlit as st
import numpy as np
import faiss
import fitz         # PyMuPDF
from openai import OpenAI

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Configuration
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
from config import FAISS_INDEX_PATH, ID_MAP_PATH
from testing_utils import visualize_faiss_output_st

# Load OpenAI client
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) Load FAISS index & ID map (once)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@st.cache_resource
def load_faiss_index(index_path: str) -> faiss.Index:
    # Windows Unicode workaround: cd into the folder
    idx = Path(index_path)
    cwd = os.getcwd()
    os.chdir(str(idx.parent))
    index = faiss.read_index(idx.name)
    os.chdir(cwd)
    return index

@st.cache_resource
def load_id_map(map_path: str) -> dict:
    with open(map_path, "r", encoding="utf-8") as f:
        return json.load(f)

index  = load_faiss_index(str(FAISS_INDEX_PATH))
id_map = load_id_map(str(ID_MAP_PATH))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) Helpers
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def extract_text_from_bytes(raw: bytes) -> str:
    """Extract text from an in-memory PDF (preserves Japanese)."""
    doc = fitz.open(stream=raw, filetype="pdf")
    return "".join(p.get_text() for p in doc)

def clean_text(txt: str) -> str:
    """Normalize whitespace."""
    return " ".join(txt.split())

def get_embedding(text: str, model: str="text-embedding-ada-002") -> list[float]:
    """
    Direct single-call embedding (no caching, no chunking).
    Relies on OpenAI to error if over token limit (~8191 tokens).
    """
    # Ensure it's a single string
    resp = client.embeddings.create(input=text.replace("\n"," "), model=model)
    return resp.data[0].embedding  # type: ignore

def find_similar(text: str, top_k: int):
    emb = np.array([get_embedding(text)], dtype="float32")
    D, I = index.search(emb, top_k)
    out = []
    for dist, idx in zip(D[0], I[0]):
        meta = id_map.get(str(int(idx)), {})
        out.append({
            "filename": meta.get("filename", "unknown"),
            "score":    float(1.0/(1.0+dist)),
        })
    return out

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) Streamlit UI
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.set_page_config(page_title="Resume Similarity Search", layout="centered")
st.title("ğŸ“„ Resume Similarity Search (æ—¥æœ¬èªå¯¾å¿œ)")
st.markdown("æ—¥æœ¬èªã®è·å‹™çµŒæ­´æ›¸PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€é¡ä¼¼å±¥æ­´æ›¸ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

uploaded = st.file_uploader("è·å‹™çµŒæ­´æ›¸PDFã‚’é¸æŠ", type=["pdf"])
top_k    = st.slider("è¡¨ç¤ºã™ã‚‹é¡ä¼¼å±¥æ­´æ›¸ã®æ•°", 1, 20, 5)

if uploaded:
    st.write(f"**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:** {uploaded.name}")
    raw = uploaded.read()
    try:
        text = clean_text(extract_text_from_bytes(raw))
        if not text:
            st.error("âš ï¸ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.subheader("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.text_area("", text[:1000], height=200)

            with st.spinner("åŸ‹ã‚è¾¼ã¿ã¨æ¤œç´¢ä¸­â€¦"):
                results = find_similar(text, top_k)

            if results:
                st.success(f"ãƒˆãƒƒãƒ— {top_k} ã®é¡ä¼¼å±¥æ­´æ›¸:")
                for i, r in enumerate(results, start=1):
                    st.write(f"{i}. **{r['filename']}** â€” ã‚¹ã‚³ã‚¢ {r['score']:.3f}")
                ##### Updated Section
                st.markdown("### Debugç”¨:çµæœã®å¯è¦–åŒ–")
                fig = visualize_faiss_output_st(
                    'Database/processed_job_description.jsonl',
                    red_filename=uploaded.name,
                    blue_filenames=[r['filename'] for r in results]
                )
                st.pyplot(fig)
                ##### End of updated section
            else:
                st.info("é¡ä¼¼ã™ã‚‹å±¥æ­´æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
else:
    st.info("ã¾ãšã¯è·å‹™çµŒæ­´æ›¸PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
